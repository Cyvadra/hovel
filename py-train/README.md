# é«˜çº§æ¨¡å‹è®­ç»ƒç³»ç»Ÿ

è¿™ä¸ªé¡¹ç›®ç°åœ¨åŒ…å«äº†å¤šç§å…ˆè¿›çš„è®­ç»ƒç­–ç•¥ï¼Œç”¨äºæå‡æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

## ğŸš€ ä¸»è¦ç‰¹æ€§

### 1. åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦
- **ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦** (`WarmUpCosineDecay`): åŒ…å«é¢„çƒ­é˜¶æ®µçš„ä½™å¼¦é€€ç«è°ƒåº¦
- **æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡è°ƒåº¦** (`ExponentialDecayWithWarmup`): åŒ…å«é¢„çƒ­é˜¶æ®µçš„æŒ‡æ•°è¡°å‡è°ƒåº¦
- **å¹³å°å­¦ä¹ ç‡è¡°å‡** (`ReduceLROnPlateau`): åŸºäºéªŒè¯æŸå¤±çš„å¹³å°è¡°å‡

### 2. æ¨¡å‹é¢„çƒ­è®­ç»ƒ
- ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡è¿›è¡Œåˆå§‹è®­ç»ƒ
- å¸®åŠ©æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸç¨³å®šæ”¶æ•›
- é¿å…è®­ç»ƒåˆæœŸçš„ä¸ç¨³å®šç°è±¡

### 3. æ¸è¿›å¼è®­ç»ƒ
- ä»å°æ‰¹é‡å¼€å§‹ï¼Œé€æ­¥å¢åŠ æ‰¹é‡å¤§å°
- æ¯ä¸ªé˜¶æ®µè‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡
- æé«˜è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½

### 4. é«˜çº§ä¼˜åŒ–å™¨
- **AdamWä¼˜åŒ–å™¨**: åŒ…å«æƒé‡è¡°å‡çš„Adamä¼˜åŒ–å™¨
- æ›´å¥½çš„æ­£åˆ™åŒ–æ•ˆæœ
- æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹

### 5. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
- å®æ—¶ç»˜åˆ¶è®­ç»ƒå†å²
- æ¯”è¾ƒä¸åŒç­–ç•¥çš„æ€§èƒ½
- å­¦ä¹ ç‡å˜åŒ–å¯è§†åŒ–

## ğŸ“ æ–‡ä»¶ç»“æ„

```
â”œâ”€â”€ train.py                    # ä¸»è¦è®­ç»ƒæ¨¡å—
â”œâ”€â”€ activation_comparison.py    # æ¿€æ´»å‡½æ•°æ¯”è¾ƒ
â”œâ”€â”€ advanced_training_demo.py   # è®­ç»ƒç­–ç•¥æ¼”ç¤º
â””â”€â”€ README_advanced_training.md # æœ¬æ–‡æ¡£
```

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬è®­ç»ƒ

```python
from train import build_model, split_data, train_model_advanced, evaluate_model

# æ„å»ºæ¨¡å‹
model = build_model(input_shape, output_units, optimizer_type='adamw')

# é«˜çº§è®­ç»ƒ
history = train_model_advanced(
    model, x_train, y_train, x_val, y_val,
    epochs=500,
    batch_size=128,
    lr_schedule='cosine'  # 'cosine', 'exponential', 'plateau'
)
```

### æ¨¡å‹é¢„çƒ­è®­ç»ƒ

```python
from train import warmup_training

# é¢„çƒ­è®­ç»ƒ
warmup_history = warmup_training(
    model, x_train, y_train, x_val, y_val, 
    warmup_epochs=20
)
```

### æ¸è¿›å¼è®­ç»ƒ

```python
from train import progressive_training

# æ¸è¿›å¼è®­ç»ƒ
training_history = progressive_training(
    model, x_train, y_train, x_val, y_val,
    batch_sizes=[64, 128, 256],
    epochs_per_stage=100
)
```

### å®Œæ•´è®­ç»ƒæµç¨‹

```python
# 1. æ¨¡å‹é¢„çƒ­
warmup_history = warmup_training(model, x_train, y_train, x_val, y_val)

# 2. æ¸è¿›å¼è®­ç»ƒ
training_history = progressive_training(model, x_train, y_train, x_val, y_val)

# 3. è¯„ä¼°æ¨¡å‹
results = evaluate_model(model, x_val, y_val)

# 4. å¯è§†åŒ–
plot_training_history([warmup_history] + training_history)
```

## ğŸ¯ è®­ç»ƒç­–ç•¥æ¯”è¾ƒ

### 1. ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦
- **ä¼˜ç‚¹**: å¹³æ»‘çš„å­¦ä¹ ç‡è¡°å‡ï¼Œé¿å…çªç„¶çš„å­¦ä¹ ç‡å˜åŒ–
- **é€‚ç”¨åœºæ™¯**: å¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡
- **å‚æ•°**: `initial_lr=1e-3`, `warmup_epochs=10`, `total_epochs=500`

### 2. æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡è°ƒåº¦
- **ä¼˜ç‚¹**: å¿«é€Ÿçš„å­¦ä¹ ç‡è¡°å‡ï¼Œé€‚åˆå¿«é€Ÿæ”¶æ•›
- **é€‚ç”¨åœºæ™¯**: éœ€è¦å¿«é€Ÿæ”¶æ•›çš„ä»»åŠ¡
- **å‚æ•°**: `initial_lr=1e-3`, `warmup_epochs=5`, `decay_rate=0.95`

### 3. å¹³å°å­¦ä¹ ç‡è¡°å‡
- **ä¼˜ç‚¹**: åŸºäºéªŒè¯æ€§èƒ½è‡ªé€‚åº”è°ƒæ•´
- **é€‚ç”¨åœºæ™¯**: éªŒè¯æŸå¤±æ³¢åŠ¨è¾ƒå¤§çš„ä»»åŠ¡
- **å‚æ•°**: `factor=0.5`, `patience=10`, `min_lr=1e-7`

### 4. æ¸è¿›å¼è®­ç»ƒ
- **ä¼˜ç‚¹**: æé«˜è®­ç»ƒç¨³å®šæ€§ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜
- **é€‚ç”¨åœºæ™¯**: å¤æ‚æ¨¡å‹æˆ–å›°éš¾æ•°æ®é›†
- **å‚æ•°**: `batch_sizes=[64, 128, 256]`, `epochs_per_stage=100`

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å›è°ƒå‡½æ•°
- **ModelCheckpoint**: è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- **EarlyStopping**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **LearningRateScheduler**: åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦
- **ReduceLROnPlateau**: å¹³å°å­¦ä¹ ç‡è¡°å‡

### å¯è§†åŒ–
- è®­ç»ƒæŸå¤±æ›²çº¿
- éªŒè¯æŸå¤±æ›²çº¿
- MAEå’ŒMSEå˜åŒ–
- å­¦ä¹ ç‡å˜åŒ–æ›²çº¿

## ğŸ”§ å‚æ•°è°ƒä¼˜å»ºè®®

### å­¦ä¹ ç‡è®¾ç½®
```python
# å¯¹äºä¸åŒè§„æ¨¡çš„æ•°æ®é›†
small_dataset = {'initial_lr': 1e-3, 'warmup_epochs': 5}
medium_dataset = {'initial_lr': 1e-3, 'warmup_epochs': 10}
large_dataset = {'initial_lr': 5e-4, 'warmup_epochs': 15}
```

### æ‰¹é‡å¤§å°è®¾ç½®
```python
# æ¸è¿›å¼è®­ç»ƒçš„æ‰¹é‡å¤§å°
batch_sizes_small = [32, 64, 128]
batch_sizes_medium = [64, 128, 256]
batch_sizes_large = [128, 256, 512]
```

### é¢„çƒ­è½®æ•°è®¾ç½®
```python
# æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´é¢„çƒ­è½®æ•°
warmup_epochs = min(20, total_epochs // 10)
```

## ğŸš€ è¿è¡Œç¤ºä¾‹

### è¿è¡Œæ¿€æ´»å‡½æ•°æ¯”è¾ƒ
```bash
python activation_comparison.py
```

### è¿è¡Œè®­ç»ƒç­–ç•¥æ¼”ç¤º
```bash
python advanced_training_demo.py
```

### è¿è¡ŒåŸºæœ¬è®­ç»ƒ
```bash
python train.py
```

## ğŸ“ˆ é¢„æœŸæ”¹è¿›

ä½¿ç”¨è¿™äº›é«˜çº§è®­ç»ƒç­–ç•¥ï¼Œé¢„æœŸå¯ä»¥è·å¾—ä»¥ä¸‹æ”¹è¿›ï¼š

1. **æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹**: é¢„çƒ­è®­ç»ƒå’Œæ¸è¿›å¼è®­ç»ƒå‡å°‘è®­ç»ƒåˆæœŸçš„ä¸ç¨³å®š
2. **æ›´å¥½çš„æ”¶æ•›æ€§èƒ½**: åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦å¸®åŠ©æ¨¡å‹æ‰¾åˆ°æ›´å¥½çš„å±€éƒ¨æœ€ä¼˜
3. **æ›´é«˜çš„æœ€ç»ˆç²¾åº¦**: AdamWä¼˜åŒ–å™¨å’Œé«˜çº§è°ƒåº¦ç­–ç•¥æå‡æ¨¡å‹æ€§èƒ½
4. **æ›´å°‘çš„è¿‡æ‹Ÿåˆ**: æ›´å¥½çš„æ­£åˆ™åŒ–å’Œæ—©åœæœºåˆ¶

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**: å‡å°‘æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨æ¸è¿›å¼è®­ç»ƒ
2. **è®­ç»ƒä¸ç¨³å®š**: å¢åŠ é¢„çƒ­è½®æ•°æˆ–é™ä½åˆå§‹å­¦ä¹ ç‡
3. **æ”¶æ•›ç¼“æ…¢**: å°è¯•ä¸åŒçš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
4. **è¿‡æ‹Ÿåˆ**: å¢åŠ æ­£åˆ™åŒ–å¼ºåº¦æˆ–ä½¿ç”¨æ—©åœ

### è°ƒè¯•æŠ€å·§

1. ç›‘æ§å­¦ä¹ ç‡å˜åŒ–
2. è§‚å¯Ÿè®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿
3. ä½¿ç”¨ä¸åŒçš„æ‰¹é‡å¤§å°è¿›è¡Œå®éªŒ
4. æ¯”è¾ƒä¸åŒä¼˜åŒ–å™¨çš„æ€§èƒ½

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v2.0**: æ·»åŠ åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦å’Œæ¨¡å‹é¢„çƒ­
- **v2.1**: æ·»åŠ æ¸è¿›å¼è®­ç»ƒå’ŒAdamWä¼˜åŒ–å™¨
- **v2.2**: æ·»åŠ å¯è§†åŒ–åŠŸèƒ½å’Œç­–ç•¥æ¯”è¾ƒ
- **v2.3**: ä¼˜åŒ–å‚æ•°è®¾ç½®å’Œæ–‡æ¡£å®Œå–„ 